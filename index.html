<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Serif', serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Serif Pro', serif;
  }
</style>
<title>CS180 Project 2</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=PT+Serif|Source+Serif+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS180 Intro to Computer Vision and Computational Photography</h1>
<h1 align="middle">Project 3 by Wentinn Liao</h1>

<div>
    
    

    <h2 align="left">Part 1. Defining Correspondences</h2>
    <p>Rather than implementing my own labeling tool, I simply used the provided one created by the former student. Because the backgrounds of the images were intentionally similar but slightly different in orientation, more points were added to ensure their alignment as well, resulting in a total of <strong>168</strong> keypoints in total. To construct the triangulation, the average of the keypoints of both images was taken and used to construct the Delaunay triangulation. The same set of simplices is then used for both images, as well as for the future warped images.</p>
    <div align="middle">
        <table>
            <tr>
                <td>
                    <img src="code/data/wenlun.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Wenlun.</figcaption>
                </td>
                <td>
                    <img src="images/Wenlun+Dad/Wenlun triangulation.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Wenlun keypoints and triangulation.</figcaption>
                </td>
            </tr>
            <tr>
                <td>
                    <img src="code/data/dad.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Dad.</figcaption>
                </td>
                <td>
                    <img src="images/Wenlun+Dad/Dad triangulation.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Dad keypoints and triangulation.</figcaption>
                </td>
            </tr>
        </table>
    </div>
    
    
    
    <h2 align="left">Part 2. Computing the "Mid-way Face"</h2>
    <p>Rather than writing separate code to compute the midway face, the code written for morphing in <strong>part 3</strong> is used to compute the midway image, with a both a warp fraction and dissolve fraction of <strong>0.5</strong>. The morph function is both more general, and done in batch with <strong>Numpy</strong> and <strong>TensorFlow</strong> operations, making it incredibly efficient, even for large image sizes and a high number of frames.</p>
    <div align="middle">
        <table>
            <tr>
                <td>
                    <img src="code/data/wenlun.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Wenlun.</figcaption>
                </td>
                <td>
                    <img src="images/Wenlun+Dad/Midway image.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Midway image.</figcaption>
                </td>
                <td>
                    <img src="code/data/dad.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Dad.</figcaption>
                </td>
            </tr>
        </table>
    </div>
    
    
    
    <h2 align="left">Part 3. The Morph Sequence</h2>
    <p>All the functions used to implement the morph sequence were written in batch, which allows us to ultimately compute a morph sequence of <strong>100 frames</strong> in less than <strong>20 seconds</strong>.</p>
    <p>First, the warp points are computed via an outer product between the warp fractionals and the difference between the image points, and adding it back to the starting image. To compute the backward affine transformations, the forward affines are computed by computing the forward affines for only the two endpoints and interpolating with the warp fractionals, and then batch inverting the sequence of forward matrices. This allows us to skip <strong>T</strong> matrix multiplications and replace them with scalar multiplications which saves a lot of time.</p>
    <p>Unfortunately, the limitations of <strong>sk.draw</strong> requires to compute the polygons serially rather than in parallel. Furthermore, different morphs causes the triangles to be slightly different in shape, meaning the total number of pixels in each triangle may be different. This is remedied by padding using <strong>tf.keras.utils.pad_sequence</strong>. To reextract and remove the padding after multiplying by the backward affine matrices however takes some work. The secret is that I don't actually ever remove the effects of the padding. Usually we augment the pixel coordinates with <strong>1</strong>s to allow affine transformations to properly do translation. However, we first do the augmentation, then pad the sequences to equal lengths with <strong>0</strong>s. Now, the padded "pixel coordinates" will always transform to <strong>0</strong>s regardless of the affine transformation, and ignoring the augmentations means that all the real pixel coordinates will map correctly and <strong>(0, 0)</strong> will map to itself. The effect this has if we ignore it is simply that the resulting warped image will steal the top-leftmost pixel from the original image, which is negligible for the reasons that it is only a single pixel in the corner, and the corner of the warp will be similar to that of the original image anyways! This trick allows us to cut computational time by around <strong>30%</strong>, over both removing the padding, and not padding in the first place.</p>
    <div align="middle">
        <table>
            <tr>
                <td>
                    <img src="code/data/wenlun.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Wenlun.</figcaption>
                </td>
                <td>
                    <img src="images/Wenlun+Dad/wenlun_dad_morph.gif" align="middle" height="360px"/>
                    <figcaption align="middle">Morph sequence.</figcaption>
                </td>
                <td>
                    <img src="code/data/dad.jpg" align="middle" height="360px"/>
                    <figcaption align="middle">Dad.</figcaption>
                </td>
            </tr>
        </table>
    </div>
    
    
    
    <h2 align="left">Part 4. The "Mean face" of a population</h3>
        <p>In order to better facilitate calculating the mean image, boundary points are added for additional structure. Specifically, a total of <strong>4k</strong> points are evenly spaced on the boundary of the image, aligned with the corners, where <strong>k = 4</strong> is chosen to be visually optimal. Additionally, the batch functions used to make <strong>part 3</strong> efficient need to be implemented in reverse. Rather than warping a single image to a batch of facial geometries as in the morph sequence, we are now warping multiple images to a single facial geometry to compute the mean face. The latter is generally faster because the time to determine which points are in the target triangle has the most overhead. The result of the average shown below.</p>
        <div align="middle">
            <img src="images/Dane averages/Dane average.jpg" align="middle" height="360px"/>
            <figcaption align="middle">Average face over the Dane dataset.</figcaption>
        </div>
        
        <p>A total of eight random samples are selected (actually nine but we ignore the middle one) to compare with the mean, which is represented in the center of the image grid. The center grid shows the original images. The leftmost grid shows each of the samples warped to the facial geometry of the mean, computed with <strong>warpFromBatch</strong> and the rightmost grid shows the mean warped to each of the facial geometries of the samples, computed with <strong>warpToBatch</strong>.</p>
        <div align="middle">
            <table>
                <tr>
                    <td>
                        <img src="images/Dane averages/Dane samples_to_mean.jpg" align="middle" height="240px"/>
                        <figcaption align="middle">Sampled faces warped to mean.</figcaption>
                    </td>
                    <td>
                        <img src="images/Dane averages/Dane samples.jpg" align="middle" height="240px"/>
                        <figcaption align="middle">Original faces from Dane dataset.</figcaption>
                    </td>
                    <td>
                        <img src="images/Dane averages/Dane mean_to_samples.jpg" align="middle" height="240px"/>
                        <figcaption align="middle">Mean warped to sampled faces.</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        
        <p>Finally, below we have my face along with the mean face interwarped. Due to differences in facial morphology resulting from the obvious difference in nationality, my face warped to the Danish mean geometry looks absolutely atrocious, but somehow the Danish mean warped to my facial geometry looks passable. Additionally below in between is a morph sequence between my face and the Danish average. Because the morph sequence also gradually dissolves a face the more it warps to the other facial geometry, the transition does not look as bad.</p>
        <div align="middle">
            <table>
                <tr>
                    <td>
                        <img src="images/Wentinn+Danes/wentinn_to_mean.jpg" align="middle" height="240px"/>
                        <figcaption align="middle">My face warped to Danish mean geometry.</figcaption>
                    </td>
                    <td>
                        <img src="images/Wentinn+Danes/wentinn_dane_morph.gif" align="middle" height="240px"/>
                        <figcaption align="middle">Morph sequence.</figcaption>
                    </td>
                    <td>
                        <img src="images/Wentinn+Danes/mean_to_wentinn.jpg" align="middle" height="240px"/>
                        <figcaption align="middle">Danish mean face warped to my geometry.</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        
        
        
        <h2 align="left">Part 5. Caricatures: Extrapolating from the mean</h2>
        <p>To generate extrapolations with respect to an anchor image, both the image geometries and image pixels warped to the anchor geometry are extrapolated. Once the target pixels and target geometries are computed, additional batch to batch functions are implemented to allow warping <strong>B</strong> different images with the same geometry to <strong>B</strong> different geometries. With eight samples, three extrapolations each are constructed with <strong>&#x03B1 = 1.5, 2,</strong> and <strong>3</strong>, where &#x03B1 = 1 represents the original image with no extrapolation, and &#x03B1 = 0 represents the anchor image.</p>
        <div align="middle">
            <table>
                <tr>
                    <td>
                        <img src="images/Extrapolations/Dane samples 2.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Original images.</figcaption>
                    </td>
                    <td>
                        <img src="images/Extrapolations/Dane extrapolations a=1.5.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Caricature with &#x03B1 = 1.5.</figcaption>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/Extrapolations/Dane extrapolations a=2.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Caricature with &#x03B1 = 2.</figcaption>
                    </td>
                    <td>
                        <img src="images/Extrapolations/Dane extrapolations a=3.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Caricature with &#x03B1 = 3.</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        
        
        
        <h2 align="left">Bells & Whistles. Caricatures: Extrapolating with a PCA basis</h2>
        <p>Extrapolation, or even modest interpolation using the Dane dataset (unsurprisingly) does not yield good results. The reason for this is that the dataset size too small. Even though intuitively it is larger than the number of significant principal components, i.e. facial feature sizes, color, hair, etc., it is definitely not large enough to plausibly approximate the ideal Gaussian distribution that lies behind PCA, especially in a <strong>921748</strong> (near 1 million) dimensional space. Due to this, the results of PCA are dominated, not by features that are strongly present in a large population, but large features that are present in an individual, e.g. a face being positioned further from the center, or lighting that causes overall face color to be significantly different. Even at a scale of <strong>&#x03B1 = 0.5</strong> (interpolation with a PCA basis vector), the image already almost exactly resembles a face directly from the dataset. Shown below are the results of the extrapolation on the first 8 principal components.</p>
        <div align="middle">
            <table>
                <tr>
                    <td>
                        <img src="images/Basis Extrapolations/Dane basis extrapolations a=0.25.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Basis extrapolation &#x03B1 = 0.25.</figcaption>
                    </td>
                    <td>
                        <img src="images/Basis Extrapolations/Dane basis extrapolations a=0.5.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Basis extrapolation &#x03B1 = 0.5.</figcaption>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/Basis Extrapolations/Dane basis extrapolations a=1.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Basis extrapolation &#x03B1 = 1.</figcaption>
                    </td>
                    <td>
                        <img src="images/Basis Extrapolations/Dane basis extrapolations a=2.jpg" align="middle" height="320px"/>
                        <figcaption align="middle">Basis extrapolation &#x03B1 = 2.</figcaption>
                    </td>
                </tr>
            </table>
        </div>
    

        
</div>
</body>
</html>
